* runnable pattern
** used for launching threads
** we create an instance of runnable interface
** we pass this instance to thread class constructor
** then start thread by calling start method of thread object
* stopping a thread
** should not call stop method on the thread
** use interrupt method
#+begin_src java
Runnable task = () -> {
    while(! Thread.currentThread().isInterrupted()) {
        // do something
    }
}
#+end_src
* producer consumer pattern
** most simple way is to use wait and notify
** a way to park thread while waiting for data to be produced, without blocking all other threads
** key held by this thread should be release why the thread is parked
* wait notify
** methods are available from the Object class
** the thread executing invocation should hold key of that object
** only way for a thread to hold key of an object is to be in synchronized block, synchronized on this object
** wait and notify cannot be invoked outside synchronized block
** calling wait
***  on lock object releases the key held by the thread, this key becomes available to other thread
*** it puts the thread in a wait state, different than when it is waiting at the beginning of synchronized block
*** only way to release a thread in wait state is to call notify on the object this thread is waiting on
** calling notify
*** releases a thread from wait and puts it in RUNNABLE state
*** if more than one thread is in wait state, the released thread is chosen randomly
*** notifyAll call releases all threads in wait state
* Thread state
** if the thread is in wait state(WAIT list) then thread scheduler should not give it time
** new, runnable, terminated, blocked, waiting, timed_waiting
** blocked thread can only run again when the key is released
** blocked -> state when thread is waiting at the entrance of synchronized block
** waiting -> state when wait method is called, no need to call notify method on lock object
*** at the entrance of synchronized block
*** guarded by a monitor that has a key
* block of code is guarded by a monitor that has a key
* cpu reads value from cache but not from main memory
* cpu architecture
** cpu
** main memory
** connected by bus
** each cpu core has l1, l2 and a common l3
** access to cache is much faster than access to main memory
* visibility
** visibility is second fundamental notion in java concurrent programming
** visibility means telling other cores not to read value from main memory but from one of the cache
** all synchronized writes are visible
* happens before link helps to order reads are writes in multi core cpu
* java memory model
** visibility means a read operation should return the values set by last write
** we need a timeline to put read and write operations on
* how to setup happens before link
** happens before link exists between all synchronized or volatile write operations and all synchronized or volatile read operations that follow
** HB link can be setup by synchronization block or volatile variable
* sample of buggy code
#+begin_src java
int x, y, r1, r2;
Object lock = new Object();

void firstMethod() {
    x=1;
    synchronized(lock) {
        y=1;
    }
}

void secondMethod() {
    synchronized(lock) {
        r1=y;
    }
    r2 = x;
}
#+end_src
* synchronization guarantees the exclusive execution of a block of code
* visibility guarantees consistency of the variables
** visibility is weaker constraint than synchronization
* all shared variables should be accessed in a synchronized way or volatile way
* false sharing
** happens because of the way caches work
** it can have tremendous effect on performance
** cache is organized in lines of data
** each line can hold 8 longs
** when a visible variable is modified in an l1 cache all the lines are markes dirty for other caches
** read on a dirty line triggers refresh on this line
** visibility problem came from multi core cpu not there in single core cpu
* synchronization is about atomicity
* volatility is about visibility
* using synchronized on singleton makes thread in another core wait if one thread already has the key
** this causes performance hit
** because of synchronized block parallel reads can also not happen
** double check locking singleton
*** because read doesn't happen in a synchronized or volatile way, there is no guarantee that read will get the value set by write
*** one can observe an object that is not fully built
**** create is a two step process
***** memory allocation
***** a - copy of pointer to singleton field
***** b - construction process
***** a and b can happen in any order
** declaring it volatile will cause the performance issues again
* best solution to singleton is to use ENUM
** used in comparator
* volatile is not alternative to synchronization
* synchronization provides atomicity while volatile doesn't
* for the code to be fully correct not only does the writes should be synchronized but reads too
* always try to synchronize your block of code with private object
* step by step producer to check if concurrent code is correct
** check for race conditions on fields of class
*** race conditions does not occur on local variables and parameters
*** if more than one thread is trying to read / write a field it means you have a race condition
*** check for happens before link
**** if the read/write volatile
**** are they synchronized
**** if you need atomicity you need to use synchronized
**** else volatility is enough
* executors
** issue with runnable pattern
*** thread is created by developer so they may not manage threads properly
*** new thread for each new task and then killed, which is expensive to create and kill
** executor pattern is created to solve this issue
*** create pools of threads and keep using them
*** we give a task to pool of threads, they choose an available thread, execute this task
** pool of threads is an instance of executor interface
** to create instances of Executor of ExecutorService we have a factory class called Executors
** most used methods of ExecutorService are
*** newSingleThreadExecutor
**** useful for reactive programming
*** newFixedThreadPoolExecutor
*** newCachedThreadPool
**** create threads on demand
**** if threads are unused the are killed in 60s
*** newScheduledThreadPool
**** can schedule a task in future
**** scheduleAtFixedRate
*** scheduleWithFixedDelay
**** delay is calculated from the end of the execution of the task
** executor has a waiting queue
** we dont have a way to know when a task is done
** a tasks execution can be cancelled if the task has not started yet
*** we remove the task from the waiting queue
** not incompatible with runnable pattern
** runnable caveats
*** method cannot return anything, no exception can be raised
*** no way to know if a task is done or not
** callable interface
*** single method call
*** executor interface does not handle callables directly
*** ExecutorService interface has a submit method that takes callables
*** submit returns future object
** future object work
*** create callable in main
*** call submit and pass callable
*** executor returns a future object that will hold the result once it is available
*** get method is blocking it will block until result is available
** 2 exceptions can be thrown from thread
*** InterrupedException
*** ExecutionException
** get method throws Interrupedexception if we pass a timeout to it
** shutting down ExecutorService
*** shutdown
**** continues to execute submitted tasks
**** executes waiting tasks
**** do not accepts new tasks
*** shutdownNow
**** halt running tasks
**** do not execute waiting tasks
*** awaitTermination
**** issues shutdown
**** after timeout it halts every thing
* Locks and semaphores
** intrinsic locking
*** if thread becomes
