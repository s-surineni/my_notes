* runnable pattern
** used for launching threads
** we create an instance of runnable interface
** we pass this instance to thread class constructor
** then start thread by calling start method of thread object
* stopping a thread
** should not call stop method on the thread
** use interrupt method
#+begin_src java
Runnable task = () -> {
    while(! Thread.currentThread().isInterrupted()) {
        // do something
    }
}
#+end_src
* producer consumer pattern
** most simple way is to use wait and notify
** a way to park thread while waiting for data to be produced, without blocking all other threads
** key held by this thread should be release why the thread is parked
* wait notify
** methods are available from the Object class
** the thread executing invocation should hold key of that object
** only way for a thread to hold key of an object is to be in synchronized block, synchronized on this object
** wait and notify cannot be invoked outside synchronized block
** calling wait
***  on lock object releases the key held by the thread, this key becomes available to other thread
*** it puts the thread in a wait state, different than when it is waiting at the beginning of synchronized block
*** only way to release a thread in wait state is to call notify on the object this thread is waiting on
** calling notify
*** releases a thread from wait and puts it in RUNNABLE state
*** if more than one thread is in wait state, the released thread is chosen randomly
*** notifyAll call releases all threads in wait state
* Thread state
** if the thread is in wait state(WAIT list) then thread scheduler should not give it time
** new, runnable, terminated, blocked, waiting, timed_waiting
** blocked thread can only run again when the key is released
** blocked -> state when thread is waiting at the entrance of synchronized block
** waiting -> state when wait method is called, no need to call notify method on lock object
*** at the entrance of synchronized block
*** guarded by a monitor that has a key
* block of code is guarded by a monitor that has a key
* cpu reads value from cache but not from main memory
* cpu architecture
** cpu
** main memory
** connected by bus
** each cpu core has l1, l2 and a common l3
** access to cache is much faster than access to main memory
* visibility
** visibility is second fundamental notion in java concurrent programming
** visibility means telling other cores not to read value from main memory but from one of the cache
** all synchronized writes are visible
* happens before link helps to order reads are writes in multi core cpu
* java memory model
** visibility means a read operation should return the values set by last write
** we need a timeline to put read and write operations on
* how to setup happens before link
** happens before link exists between all synchronized or volatile write operations and all synchronized or volatile read operations that follow
** HB link can be setup by synchronization block or volatile variable
* sample of buggy code
#+begin_src java
int x, y, r1, r2;
Object lock = new Object();

void firstMethod() {
    x=1;
    synchronized(lock) {
        y=1;
    }
}

void secondMethod() {
    synchronized(lock) {
        r1=y;
    }
    r2 = x;
}
#+end_src
* synchronization guarantees the exclusive execution of a block of code
* visibility guarantees consistency of the variables
** visibility is weaker constraint than synchronization
* all shared variables should be accessed in a synchronized way or volatile way
* false sharing
** happens because of the way caches work
** it can have tremendous effect on performance
** cache is organized in lines of data
** each line can hold 8 longs
** when a visible variable is modified in an l1 cache all the lines are markes dirty for other caches
** read on a dirty line triggers refresh on this line
** visibility problem came from multi core cpu not there in single core cpu
* synchronization is about atomicity
* volatility is about visibility
* using synchronized on singleton makes thread in another core wait if one thread already has the key
** this causes performance hit
** because of synchronized block parallel reads can also not happen
** double check locking singleton
*** because read doesn't happen in a synchronized or volatile way, there is no guarantee that read will get the value set by write
*** one can observe an object that is not fully built
**** create is a two step process
***** memory allocation
***** a - copy of pointer to singleton field
***** b - construction process
***** a and b can happen in any order
** declaring it volatile will cause the performance issues again
* best solution to singleton is to use ENUM
** used in comparator
* volatile is not alternative to synchronization
* synchronization provides atomicity while volatile doesn't
* for the code to be fully correct not only does the writes should be synchronized but reads too
* always try to synchronize your block of code with private object
* step by step producer to check if concurrent code is correct
** check for race conditions on fields of class
*** race conditions does not occur on local variables and parameters
*** if more than one thread is trying to read / write a field it means you have a race condition
*** check for happens before link
**** if the read/write volatile
**** are they synchronized
**** if you need atomicity you need to use synchronized
**** else volatility is enough
