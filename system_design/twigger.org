* Functional requirements
** tweet
** re-tweet
** follow
** search
* Non functional requirements
** read heavy
** fast rendering of timeline
** fast tweet
** lag ok in terms of finding new tweets in search
** scale
* categorizing users
** famous
*** actors, politician, ceo
** active
*** who have used twitter in 2 days
** live
*** people who have app opened now
** passive
*** who have not accessed app in long time and not famous
** inactive
* when designing read heavy system either precompute information or cache as much as possible
* user onboarding
** user service is the source of truth for all user related information
** powers login, registration, profile screen etc
** exposes apis to get info regarding users (individual and bulk apis)
** uses clustered mysql database
*** relational data
*** doesn't change frequently
** uses cache to store user information too
* user follow
** powered by a service called graph service
** has apis like follow a user, get my followers, get who I follow etc
** uses separate mysql cluster
** consider sharing
** structure would be like userid, follower id, datetime
** cache this data too
*** user id
*** followers of this user
*** who this user follows
* analytics
** track the tweet user is spending time on
** tweets user is liking
* live user service
** keeps web socket open with live users
** whenever someone tags live user
** or tweet send by user this person follows
** we are also capturing how long the user is live
** if user disconnects this service puts that info into kafka and is collected by user service
*** the live user is then switched to active user
* post tweet flow
** if tweet contains image or video asset service takes care of them
*** it uploads them to cloud/anywhere and displays them(similar to netflix and youtube)
** if tweet contains url we use url shortner service
** tweet injestion service stores and retrieves tweets
*** uses cassandra to store tweets
*** just stores tweet doesn't provide apis( doesn't even retrieve?)
*** publishes event to kafka
** tweet service
*** has apis to retrieve/display tweets
*** uses same cassandra as tweet injestion service
*** powers timeline
** timeline
*** series of tweets
** 2 views for a user to see tweets
*** user timeline
*** home timeline
**** it could select * where userid == users I follow
**** this would be a costly operation at runtime
**** precalculate active users timelines
**** whenever there is a tweet get their followers and precalculates their timeline and cache it
**** tweet service uses graph service to get users followers
**** if we calculate all followers timelines it takes lot of data
**** so only calculate active users timeline and put it in redis
*** Passive user timeline
**** when user logs in it goes to timeline service
**** timeline service queries user service to find out if the user is active or passive
**** if user is passive it creates timeline from scratch as it is not available in redis
**** procedure
***** queries graph service for the users this user is following
***** queries tweet service to get tweets of all these users
***** once tweets are retrieved it stores them back into redis and returns the result
*** Live users
**** tweet processor know whose timeline to be updated
**** if user is live, it puts back event back into kafka
**** web socket service listens to this event and sends notification to user
*** for famous users we won't update their followers timelines automatically as they will have millions of users
**** the timeline service merges timeline with normal users tweets(from redis) and famous users tweets
**** before showing to user it gets famous users tweets this user follows using graph service and tweet service
**** updates redis cache, and sends to UI
**** it also stores timestamp at which it did this merge
**** so if more time is elapsed (>5 min ) it will do re-merge else sends the same cached data
*** when a famous user tweets don't update cache of all users but only of other famous users
** search and analytics
*** during tweet ingestion only search consumer listens to event and stores it in elastic search
*** on the other end user search via search ui, which will be handled by search service
*** when returning results search service caches them also as many people for search for samething at a time
*** At the same ingestion time we can have a spark streaming consumer running and check most common words
**** this data can be sent to trend service
**** we can use redis for storage as this data is temporary
*** add hadoop cluster for more analytics.
**** newsletter
**** weekly cron job to send newsletter to passive users
