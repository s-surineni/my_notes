* Functional requirements
** should be able to upload videos
** home page and search
** play videos
** support all devices laptop, mobile, watch
* non functional requirements
** no buffering
*** low latency
*** high availability
** increase user session time
** good recommendation engine
*** big feature as we need to support (device * dimension * file * quality * frames per second * audio bit rate) type combinations
** consumers of the platform
*** clients - devices
**** have some functionality to do some smart things
*** users
*** production houses
* how client works
** wont download whole video
** downloads some chunk and plays it
** while the chunk is being played it downloads further video
** client figures out what device it is on and what video formats are supported
** if client supports multiple formats it selects one
** if client starts with high quality version of video, while playing if the next part of the video doesn't come, it switches to lower version
** above is called adaptive bitrate streaming
* architecture helping production houses
** starts uploading video from outside from ui
** for large files upto 40 gb this process doesn't work. so we use sftp
** ui talks to asset onboarding service
** asset onboarding service uploads video to s3
** cassandra contains all the info about all the videos
*** owner, description, images, thumbnails
** after file is uploaded it publishes event
** multiple systems listen to above event
** content processor = workflow engine
** first chunks the file
** uses kafka to send out events
** next comes to content filter
*** piracy, nudity, abusive language
** content tagger
*** tags, thumbnails
*** transcoder
*** quality converter
*** upload component to CDN
**** contains info like movie name, format, timerange
*** all the tags from multiple chunks will be aggregated by spark streaming service, filter top 10 tags
** asset service
*** keeps track of how many chunks are there, which chunk is in which state
*** stores all the info in cassandra
*** sends notification to user saying video is ready for viewing
* services powering user facing products
** login flow
** handled by user service
** user service is source of truth for user related information
** uses mysql database
*** data is name, email, subscriptions, country
** also caches data using redis
** we save device and geography of login and use the data for analytics
** home screen
*** powered by homepage service and search service
*** if more people are going to second page that means results are not good enough
*** this is tracked by analytics service
* Playing video
** host identity service queries asset service to get video from cdn which is closest to user device
** 2 types of cdn main and local to a place
** we can capture the info about the legth they have watched and use it as proxy for ratings
*** this task is done by stream stats logger service
* once the video processing is done asset service pushes event to kafka
** this event will have lot of info about movie
** search consumer service listens to this event
** converts it into format for search friendliness
** search uses elastic search, because we need fuzzy search
* search flow
** searches a string in home screen
** string is forwarded to search service
** search consumer and service use same schema
** searches for the input in multiple fields
** it could have a flag which checks age filter - I don't this this is the right place for age filter
** it checks with user service about users age
** it returs the info to ui
* all the components are horizontally scalable
* content tagger info comes to kafka
** spark streaming service listens to event for tags
** it takes previous 30 min of events and reduces tags by movie id
** once we get tag info, spark sends back info to kafka, which asset service will listen and stores in cassandra
* why cassandra
** handles massive amounts of reads and writes
** follows no master strategy
** good for small number of queries and queries by partition key
** bad at random queries, aggregations
* content tagger
** also chooses thumbnails for the video
** each thumbnail event is sent to kafka
** spark listens to these events and forwards them into hadoop cluster
** when we show home page or search results random thumbnails will be shown to different users
** analytics service could also send info about which thumbnail works best
** using hadoop we can also get which category of users like which thumbnail and show them that
* user classification
** based on videos they liked, put the genre
** store this information in cassandra
** can be used for recommendations
** the other parameter for classification is the search use is doing
** these analytics can be used in recommendation engine
*** uses apache spark cluster
** collaborative filtering
** use outputs from recommendation engine into homepage
** can be used to both rows and content of the rows
** we can check if recommendations are working using analytics service
* geo tagging user finger printing
* traffic predictor
** how to load, what data to load in local cdn
** predict what people are going to watch, and cache it before hand
** saves bandwidth and low buffering nfr
** new launch could be one input
** another inputs come from analytics
** after predicting what videos will be watched in different localities it puts event into kafka
* cdn writer
** looks at event from traffic predictor and copies the videos
** it gets event saying lc1 requires chunks c1, c2, c3
** queries asset service and finds out what all are missing
** we are communicating in terms of chunks so we only take care of required formats and quality
** how is data copied
** there will be 1 s3 and 2 main cdns
** instead of copying all chunks from s3 to local cdns. distribute chunks among LC and
** if we use s3 our cost will increase, single point of failure
** do the transfer when there is low load
** optimization netflix is doing giving boxes to isps
* micro services
** initial days
*** load balancer
*** apache
*** tomcat
*** java web
*** jdbc
*** database
** difficult to diagonise issues in monolith
** monolithic database
** lack of agility due to tightly coupled architecture
** definition by martin fowler
*** the microservice architectural style is an approach to developinga single application as a suite of small services each running its own process and communicating with lightweight mechanisms often an http resource API
** benefits
*** separation of concerns
*** modularity
*** encapsulation
*** scalability
*** workload partitioning
*** virtualization and elasticity
**** automated operations
**** on demand provisioning
** netflix architecture
*** edge
**** ELB
**** Proxy - Zuul does dynamic routing
**** legacy tier NCCP
**** API
*** middle tier and platform
**** product
***** bucket testing - A/B testing
***** Subscriber - info about user profiles
***** recommendations
**** Platform
***** Routing - for microservices to find each other
***** configuration - dynamic configuration
***** crypto
**** Persistence
***** Cache
***** Database
*** Microservices are an abstraction
**** they included application
**** database
**** client libraries - data access?
**** EVCache client
**** Client library - Orchestration?
**** Client application?
** challenges and solutions
*** dependency
**** intra service requests
***** we are going to call other process in another box.
***** there could be network latency, congestion, failure
***** logical or scaling failure
***** if one service fails if there are no defence mechanisms it can cascade the failure to other services
**** Solution - Hystrix
***** structured way of handling timeouts and retries
***** if we can't call serviceB return static response
***** isolated thread pools and circuits?
***** How to know if it works
****** inoculation - inject dead virus FIT tests - Fault injection test in production
****** synthetic transactions
****** % of live traffic - load testing
****** enforced throughout call paths - direct or indirect
****** how do we constrain testing scope
*** scale
*** variance
*** change
